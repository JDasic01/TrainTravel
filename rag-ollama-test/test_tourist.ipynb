{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi import FastAPI\n",
    "import json\n",
    "import torch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import Neo4jVector\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "    ollama_backend = \"cuda\"\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    ollama_backend = \"cpu\"\n",
    "\n",
    "# 1Ô∏è‚É£ CONNECT TO NEO4J DATABASE\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7689\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"password\",\n",
    "    refresh_schema=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Function to ingest tourist guides into Neo4j\n",
    "def ingest_guide(text):\n",
    "    \"\"\"Extracts entities from a tourist guide and stores them in Neo4j.\"\"\"\n",
    "    \n",
    "    documents = [Document(page_content=text)]\n",
    "    llm = ChatOllama(model=\"mistral\", temperature=0, backend=ollama_backend)\n",
    "    graph_transformer = LLMGraphTransformer(llm=llm)\n",
    "    graph_documents = graph_transformer.convert_to_graph_documents(documents)\n",
    "    graph.add_graph_documents(graph_documents, baseEntityLabel=True, include_source=True)\n",
    "\n",
    "    # Use the correct import and remove backend parameter if it is not supported\n",
    "    embed = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "    vector_index = Neo4jVector.from_existing_graph(\n",
    "        embedding=embed,\n",
    "        url=\"bolt://localhost:7689\",\n",
    "        username=\"neo4j\",\n",
    "        password=\"password\",\n",
    "        search_type=\"hybrid\",\n",
    "        node_label=\"Document\",\n",
    "        text_node_properties=[\"text\"],\n",
    "        embedding_node_property=\"embedding\"\n",
    "    )\n",
    "    \n",
    "    global vector_retriever\n",
    "    vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ FUNCTION TO QUERY NEO4J\n",
    "def query_neo4j(question):\n",
    "    \"\"\"Extracts entities from a question and retrieves relationships from Neo4j.\"\"\"\n",
    "\n",
    "    class Entities(BaseModel):\n",
    "        names: list[str] = Field(..., description=\"Extracted entities from text\")\n",
    "\n",
    "    # Define prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Extract locations, events, foods, and attractions from the question.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    # Use ChatOllama\n",
    "    llm = ChatOllama(model=\"mistral\", format=\"json\", temperature=0, backend=ollama_backend)\n",
    "\n",
    "    # Invoke model with structured output\n",
    "    response = llm.invoke(prompt.format(question=question))\n",
    "    print(\"üìù Raw LLM Response:\", response.content)\n",
    "\n",
    "    # Ensure response is valid\n",
    "    if not response or not response.content:\n",
    "        print(\"‚ö†Ô∏è No response from Ollama!\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # Parse JSON response\n",
    "        parsed_response = json.loads(response.content)\n",
    "        entities = parsed_response.get(\"names\", [])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ùå Failed to parse JSON: {response.content}\")\n",
    "        return \"\"\n",
    "\n",
    "    print(\"‚úÖ Retrieved Entities:\", entities)\n",
    "    \n",
    "    result = []\n",
    "    for entity in entities:\n",
    "        query_response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL {\n",
    "                WITH $entity AS entity\n",
    "                MATCH (p:Place {id: entity})-[:*]->(e)\n",
    "                RETURN p.id AS source_id, type(r) AS relationship, e.id AS target_id\n",
    "                LIMIT 50\n",
    "            }\n",
    "            RETURN source_id, relationship, target_id\n",
    "            \"\"\",\n",
    "            {\"entity\": entity},\n",
    "        )\n",
    "\n",
    "        # Handle empty results\n",
    "        if not query_response:\n",
    "            result.append(f\"No relationships found for entity: {entity}\")\n",
    "        else:\n",
    "            result.extend([f\"{el['source_id']} - {el['relationship']} -> {el['target_id']}\" for el in query_response])\n",
    "\n",
    "    return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ FUNCTION FOR HYBRID SEARCH (Neo4j Graph + Vector Embeddings)\n",
    "def query_tourist_guide(question):\n",
    "    \"\"\"Performs hybrid search using Neo4j graph data and vector embeddings.\"\"\"\n",
    "\n",
    "    def full_retriever(question: str):\n",
    "        graph_data = query_neo4j(question)\n",
    "        \n",
    "        vector_query = \"\"\"\n",
    "        CALL {\n",
    "            WITH $query AS query\n",
    "            CALL db.index.vector.queryNodes($index, $k, $embedding) \n",
    "            YIELD node, score \n",
    "            WITH collect({node: node, score: score}) AS nodes, max(score) AS max \n",
    "            UNWIND nodes AS n \n",
    "            RETURN n.node AS node, (n.score / max) AS score\n",
    "        }\n",
    "        RETURN node.text AS text, node.metadata AS metadata, score\n",
    "        \"\"\"\n",
    "\n",
    "        vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "        \n",
    "        return f\"Graph data: {graph_data}\\nVector data: {'#Document '.join(vector_data)}\"\n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    llm = ChatOllama(model=\"llama3\", temperature=0, backend=ollama_backend)\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return chain.invoke({\"context\": full_retriever(question), \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting tourist guide into Neo4j...\n"
     ]
    }
   ],
   "source": [
    "# Example tourist guide data\n",
    "guide_text = \"\"\"\n",
    "Babina Greda is probably the best kept secret of eastern Croatia.\n",
    "The valleys are greener, the traditional kulen even more delicious, and the girls have the prettiest smiles.\n",
    "The Slavonian treasure chest will surprise you wherever you go.\n",
    "\n",
    "Gatherings of Stanari\" (Stanarski susreti)\n",
    "End of August (beginning of September) is reserved for the \"Gatherings of Stanari\".\n",
    "This event revives memories of life on traditional farms called \"stanovi\".\n",
    "Visitors enjoy competitions in farming skills, cooking duels, and traditional dish preparation.\n",
    "\"\"\"\n",
    "\n",
    "# Ingest guide data into Neo4j\n",
    "print(\"Ingesting tourist guide into Neo4j...\")\n",
    "ingest_guide(guide_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying: What is Babina Greda known for?\n",
      "\n",
      "üìù Raw LLM Response: {\n",
      "    \"locations\": [\"Babina Greda\"],\n",
      "    \"events\": [],\n",
      "    \"foods\": [],\n",
      "    \"attractions\": []\n",
      "}\n",
      "‚úÖ Retrieved Entities: []\n",
      "Final Answer:\n",
      " According to the provided text, Babina Greda is probably the best kept secret of eastern Croatia. It is described as having greener valleys, more delicious traditional kulen (a type of sausage), and prettier smiles from the girls. Additionally, it is mentioned that the Slavonian treasure chest will surprise visitors wherever they go.\n",
      "\n",
      "Querying: What traditional events happen in Slavonia?\n",
      "\n",
      "üìù Raw LLM Response: {\n",
      "  \"locations\": [\"Slavonia\"],\n",
      "  \"events\": [\"traditional events\"]\n",
      "}\n",
      "‚úÖ Retrieved Entities: []\n",
      "Final Answer:\n",
      " According to the provided text, there is no specific mention of traditional events happening in Slavonia. However, it does mention that Babina Greda is referred to as the \"Slavonian treasure chest\" and that the region has valleys that are greener, kulen that is more delicious, and girls with prettier smiles. Additionally, it mentions the \"Gatherings of Stanari\" event which takes place in Stanari, but it's not explicitly stated that this event happens in Slavonia.\n",
      "\n",
      "Querying: Tell me about food in Dalmatia.\n",
      "\n",
      "üìù Raw LLM Response: {\n",
      "    \"locations\": [\"Dalmatia\"],\n",
      "    \"events\": [],\n",
      "    \"foods\": [\"Food in Dalmatia\"],\n",
      "    \"attractions\": []\n",
      "}\n",
      "‚úÖ Retrieved Entities: []\n",
      "Final Answer:\n",
      " There is no mention of Dalmatia in the provided context. The text only mentions Babina Greda and Slavonia, which are regions in eastern Croatia. Therefore, I cannot provide information about food in Dalmatia based on this context.\n"
     ]
    }
   ],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"What is Babina Greda known for?\",\n",
    "    \"What traditional events happen in Slavonia?\",\n",
    "    \"Tell me about food in Dalmatia.\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nQuerying: {q}\\n\")\n",
    "    response = query_tourist_guide(q)\n",
    "    print(\"Final Answer:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
